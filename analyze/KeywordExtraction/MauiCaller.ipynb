{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below code was for development purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "p = Popen([\"java\", \"-jar\", \"-Xmx1024m\", \"maui-standalone-1.1-SNAPSHOT.jar\", \n",
    "         \"train\", \"-l\",\"data/jobscan/train\", \"-m\",\"data/models/keyword_extraction_model_Steph3\",\"-v\",\"ACMTaxonomySkosExtended2.rdf\",\"-f\",\"skos\",\"-o\",\"1\"], stdout=PIPE, stderr=STDOUT)\n",
    "#for line in p.stdout:\n",
    " #   print line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/steph/Google Drive/MIDS/Capstone/JobFictionLocal/job-fiction/analyze/KeywordExtraction\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "08 Apr 2016 15:15:59  INFO MauiTopicExtractor - Extracting keyphrases with options: \n",
      "\n",
      "08 Apr 2016 15:15:59  INFO MauiTopicExtractor - -l data/jobscanManualClean/test -m data/models/keyword_extraction_model_Steph2 -v ACMTaxonomySkosExtended2.rdf -f skos -e default -i en -n 30 -c 0.0 -t com.entopix.maui.stemmers.PorterStemmer -s com.entopix.maui.stopwords.StopwordsEnglish   \n",
      "\n",
      "08 Apr 2016 15:15:59  INFO MauiTopicExtractor - -- Loading the model... \n",
      "\n",
      "08 Apr 2016 15:15:59  INFO MauiTopicExtractor - --- Loading the vocabulary...\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - Error running MauiTopicExtractor..\n",
      "\n",
      "\tat com.entopix.maui.main.MauiTopicExtractor.loadDocuments(MauiTopicExtractor.java:456)\n",
      "\n",
      "\tat com.entopix.maui.main.MauiTopicExtractor.main(MauiTopicExtractor.java:642)\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -l <directory name>\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tSpecifies name of directory.\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -m <model name>\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tSpecifies name of model.\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -v <vocabulary name>\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tSpecifies vocabulary name.\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -f <vocabulary format>\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tSpecifies vocabulary format.\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -e <encoding>\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tSpecifies encoding.\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -i <document language>\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tSpecifies document language (en (default), es, de, fr).\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -n\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tSpecifies number of phrases to be output (default: 5).\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -c\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tSpecifies cut off probability for each topic (default: 0.0).\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -t <name of stemmer class>\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tSet the stemmer to use (default: SremovalStemmer).\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -s <name of stopwords class>\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tSet the stopwords class to use (default: EnglishStopwords).\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -s\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tTurns serialization on.\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -b\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tBuilds global dictionaries for computing TFIDF from the test collection.\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - -a\n",
      "\n",
      "08 Apr 2016 15:16:05 ERROR MauiTopicExtractor - \tAlso write stemmed phrase and score into \".key\" file.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import re\n",
    "p = Popen([\"java\", \"-jar\", \"-Xmx1024m\", \"maui-standalone-1.1-SNAPSHOT.jar\", \n",
    "           \"test\", \"-l\",\"data/jobscanManualClean/test\", \"-m\",\"data/models/keyword_extraction_model_Steph2\",\n",
    "           \"-v\",\"ACMTaxonomySkosExtended2.rdf\",\"-f\",\"skos\",\"-n\",\"30\"], stdout=PIPE, stderr=STDOUT)\n",
    "for line in p.stdout:\n",
    "    if line.find(\"MauiTopicExtractor\")<>-1:\n",
    "           print line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import re\n",
    "p = Popen([\"java\", \"-jar\", \"-Xmx1024m\", \"maui-standalone-1.1-SNAPSHOT.jar\", \n",
    "         \"test\", \"-l\",\"data/jobscanManualClean/train\", \"-m\",\"data/models/keyword_extraction_model\",\n",
    "           \"-v\",\"ACMTaxonomySkos.rdf\",\"-f\",\"skos\",\"-n\",\"30\"], stdout=PIPE, stderr=STDOUT)\n",
    "results={}\n",
    "for line in p.stdout:\n",
    "    if line.find(\"MauiTopicExtractor\")<>-1:\n",
    "        if line.find(\"Processing document\")<>-1:\n",
    "            #open a new doc\n",
    "            doc= line.split(\"Processing document: \")[-1].split(\"\\n\")[0]\n",
    "            kw={}\n",
    "        elif line.find(\"Topic \")<>-1:\n",
    "            key=line.split(\"Topic \")[-1].split( \" 1 \")[0]\n",
    "            value=line.split( \" 1 \")[-1].split(\" > \")[0]\n",
    "            kw[key]=value\n",
    "    results[doc]=kw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from subprocess import Popen, PIPE, STDOUT\n",
    "import os,time\n",
    "import json\n",
    "\n",
    "pathToMaui=\"/Users/steph/Google Drive/MIDS/Capstone/JobFictionLocal/job-fiction/analyze/KeywordExtraction/\"\n",
    "# Function to train a MAUI model. \n",
    "# Input: \n",
    "# - path to training file, \n",
    "# - suffix so we can generate our own model\n",
    "# - minimum number of occurence\n",
    "# Output:\n",
    "# - path to model file\n",
    "\n",
    "def trainMaui(pathToTrain, modelID, minOccurence):\n",
    "    pathToModel=pathToMaui+\"data/models/keyword_extraction_model_\"+modelID\n",
    "    p = Popen([\"java\", \"-jar\", \"-Xmx1024m\", pathToMaui+\"maui-standalone-1.1-SNAPSHOT.jar\", \n",
    "         \"train\", \"-l\",pathToTrain, \"-m\",pathToModel,\n",
    "               \"-v\",pathToMaui+\"ACMTaxonomySkosExtended2.rdf\",\"-f\",\"skos\",\"-o\",str(minOccurence)], stdout=PIPE, stderr=STDOUT)\n",
    "    for line in p.stdout:\n",
    "        if line.find(\"WARN\"):\n",
    "            continue\n",
    "        print line\n",
    "    return pathToModel\n",
    "\n",
    "\n",
    "# Function to test a MAUI model. \n",
    "# Input: \n",
    "# - path to test file, \n",
    "# - modelID for differenting models (so we can work on different model)\n",
    "# - maximum number of keywords to return\n",
    "# Output:\n",
    "# - A JSON containing the keywords\n",
    "\n",
    "def testMaui(pathToTest, modelID, numKw):\n",
    "    pathToModel=pathToMaui+\"data/models/keyword_extraction_model_\"+modelID\n",
    "    p = Popen([\"java\", \"-jar\", \"-Xmx1024m\", pathToMaui+\"maui-standalone-1.1-SNAPSHOT.jar\", \n",
    "         \"test\", \"-l\",pathToTest, \"-m\",pathToModel,\n",
    "           \"-v\",pathToMaui+\"ACMTaxonomySkosExtended2.rdf\",\"-f\",\"skos\",\"-n\",str(numKw)], stdout=PIPE, stderr=STDOUT)\n",
    "    results={}\n",
    "    kw={}\n",
    "    doc=\"\"\n",
    "    init=0\n",
    "    \n",
    "    gen=(line for line in p.stdout if line.find(\"MauiTopicExtractor\")<>-1 )\n",
    "    for line in gen:\n",
    "        if line.find(\"Processing document\")<>-1:\n",
    "            #open a new doc\n",
    "            doc= line.split(\"Processing document: \")[-1].split(\"\\n\")[0]\n",
    "            kw={}\n",
    "            continue\n",
    "\n",
    "        elif line.find(\"Topic \")<>-1:\n",
    "            key=line.split(\"Topic \")[-1].split( \" 1 \")[0]\n",
    "            \n",
    "            key=key.replace(\".\",\" \")#removing . because mongodb does not like dot in keys\n",
    "\n",
    "            value=line.split( \" 1 \")[-1].split(\" > \")[0]\n",
    "            kw[key]=value\n",
    "            init=1\n",
    "        if init:\n",
    "            results[doc]=kw\n",
    "    return json.dumps(results)\n",
    "\n",
    "# Function takes a JSON, save it into a directory and call the testMaui function.\n",
    "# Query should be in the form of {\"jobID1\":\"summary\",\"jobID2\":\"summary2\",...}\n",
    "# You can choose the model. Default is Steph2\n",
    "def mauiTopicClf(query,model=\"Steph2\",thres1=0.6,thres2=0.2):\n",
    "    #create a temporary directory for MAUI to work in\n",
    "    if not os.path.exists(\"workbench\"):\n",
    "        os.makedirs(\"workbench\")\n",
    "    # load the query and split each document into a separate file\n",
    "    data=json.loads(query)\n",
    "    for k,v in data.iteritems():\n",
    "        with open(\"workbench/\"+k+\".txt\",'w') as recFile:\n",
    "            recFile.write(v)\n",
    "    # call the Maui wrapper on these files\n",
    "    response= json.loads(testMaui(\"workbench\", model, 40))\n",
    "    # remove the working directory\n",
    "    shutil.rmtree(\"./workbench\")\n",
    "    \n",
    "\n",
    "    results={}\n",
    "    for k,v in response.iteritems():\n",
    "        key=k.split(\".txt\")[0]\n",
    "        mustHave={}\n",
    "        niceHave={}\n",
    "        exclude={}\n",
    "        keywords={}\n",
    "        for k2,v2 in v.iteritems():    \n",
    "            if float(v2)>thres1:\n",
    "                mustHave[k2]=float(v2)\n",
    "            elif float(v2)>thres2:\n",
    "                niceHave[k2]=float(v2)\n",
    "            else:\n",
    "                exclude[k2]=float(v2)\n",
    "            keywords['MustHave']= mustHave\n",
    "            keywords['NiceHave']= niceHave\n",
    "            keywords['Excluded']= exclude\n",
    "        results[key]=keywords\n",
    "    \n",
    "    return json.dumps(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 2496\r\n",
      "-rw-r--r--  1 steph  staff  270079 Mar 14 22:17 keyword_extraction_model\r\n",
      "-rw-r--r--  1 steph  staff  271014 Apr  8 11:57 keyword_extraction_model_Steph\r\n",
      "-rw-r--r--  1 steph  staff  270990 Apr  8 15:20 keyword_extraction_model_Steph2\r\n",
      "-rw-r--r--  1 steph  staff  458496 Apr  9 12:25 keyword_extraction_model_Steph3\r\n"
     ]
    }
   ],
   "source": [
    "!ls -l data/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/steph/Google Drive/MIDS/Capstone/JobFictionLocal/job-fiction/analyze/KeywordExtraction/data/models/keyword_extraction_model_Steph3\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Train a Maui model\n",
    "pathToTrain=pathToMaui+\"data/jobscan/train\"\n",
    "print trainMaui(pathToTrain,\"Steph3\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "global name 'shutil' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-ebcafd400a52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'{\"jobID1\":\"On your first day, we ll expect you to have: Deep understanding of big data challenges. Built solutions using Amazon Web Services, Redshift, S3, EMR, etc.Experience with Hadoop, Map/Reduce and Hive Expertise in SQL, SQL tuning, schema design, Python and ETL processesSolid understanding utilizing Web Services and Application Programming Interfaces (APIs) Experience in test automation and ensuring data quality across multiple datasets used for analytical purposes A graduate degree in Computer Science or similar discipline Commit code to open source projects Experience retrieving data from remote systems via API calls (eg REST) Experience with test automation and continuous build It s great, but not required, if you have: Experience with Tableau Have worked in a Marketing Org Have worked with Data Scientists\"}'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmauiTopicClf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-0edee3afe74c>\u001b[0m in \u001b[0;36mmauiTopicClf\u001b[0;34m(query, model, thres1, thres2)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mresponse\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestMaui\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"workbench\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m40\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;31m# remove the working directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 79\u001b[0;31m     \u001b[0mshutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrmtree\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./workbench\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     80\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: global name 'shutil' is not defined"
     ]
    }
   ],
   "source": [
    "# Test the classifier\n",
    "test='{\"jobID1\":\"On your first day, we ll expect you to have: Deep understanding of big data challenges. Built solutions using Amazon Web Services, Redshift, S3, EMR, etc.Experience with Hadoop, Map/Reduce and Hive Expertise in SQL, SQL tuning, schema design, Python and ETL processesSolid understanding utilizing Web Services and Application Programming Interfaces (APIs) Experience in test automation and ensuring data quality across multiple datasets used for analytical purposes A graduate degree in Computer Science or similar discipline Commit code to open source projects Experience retrieving data from remote systems via API calls (eg REST) Experience with test automation and continuous build It s great, but not required, if you have: Experience with Tableau Have worked in a Marketing Org Have worked with Data Scientists\"}'\n",
    "\n",
    "mauiTopicClf(test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
